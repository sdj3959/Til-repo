## 0921 Full-Stack: AI Integration and Application Polish

---

### ✅ 1. Spring AI를 이용한 LLM(대규모 언어 모델) 통합

*   **Spring AI** 프로젝트를 도입하여, 애플리케이션에 AI 모델의 강력한 기능을 손쉽게 통합하고, 이를 통해 코드 리뷰, Q&A 등 지능적인 기능을 제공했습니다.

1.  **Spring AI 추상화**:
    *   Spring AI는 OpenAI, Gemini 등 특정 AI 공급업체에 대한 종속성을 줄여주는 **추상화된 API**를 제공합니다.
    *   **`ChatClient`**라는 공통 인터페이스를 통해 코드를 작성하면, `application.yml`의 설정 변경만으로 AI 공급업체를 유연하게 전환할 수 있습니다.

2.  **AI 응답 고도화 (구조화된 데이터 및 가드레일)**:
    *   **구조화된 JSON 응답**: AI에게 응답을 반드시 **특정 JSON 형식**으로 반환하도록 **프롬프트 엔지니어링**을 적용했습니다. 백엔드는 이 JSON 응답을 파싱하여 구조화된 DTO로 변환한 후 프론트엔드에 전달함으로써, 데이터 활용성을 극대화했습니다.
    *   **AI 가드레일 (Guardrails)**: AI가 서비스의 목적과 범위 내에서만 동작하도록 시스템 프롬프트에 **"도메인 제한", "비도메인 요청 거절"**과 같은 강력한 규칙을 설정하여, AI 응답의 일관성과 안정성을 확보했습니다.

---

### ✅ 2. AI 대화 기록 관리 및 컨텍스트 유지

*   단발적인 AI 요청 처리를 넘어, 사용자와 AI 간의 대화를 관리하고, AI가 이전 대화 내용을 기억하여 더 맥락에 맞는 답변을 생성하도록 기능을 고도화했습니다.

1.  **대화 히스토리 영속성**:
    *   **`AIConversation` 엔티티**를 설계하여, 사용자와 AI 간의 대화(프롬프트, 응답 등)를 데이터베이스에 **영속적으로 저장**했습니다.
    *   이를 통해 사용자는 과거 대화 기록을 언제든지 다시 조회할 수 있는 **히스토리 기능**의 기반을 마련했습니다.

2.  **대화 컨텍스트(Context) 유지**:
    *   LLM은 기본적으로 Stateless이지만, 프론트엔드에서 새로운 질문을 보낼 때 **이전 대화 내용의 요약본**을 함께 전송하는 방식으로 **대화의 맥락을 유지**했습니다.
    *   백엔드는 이 컨텍스트를 프롬프트에 포함하여 AI에게 더 풍부한 정보를 제공함으로써, 더 정확하고 맥락에 맞는 답변을 유도했습니다.

---

### ✅ 3. API 안정성 확보 및 문서화

*   안정적인 서비스 운영과 효율적인 협업을 위해 API에 대한 **보호 장치**와 **문서화**를 추가했습니다.

1.  **API 레이트 리미터 (Rate Limiter)**:
    *   악의적인 사용자의 과도한 요청(어뷰징)으로부터 서버를 보호하기 위해, 특정 시간 동안 사용자별 API 호출 횟수를 제한하는 **레이트 리미터**를 **`HandlerInterceptor`**를 통해 구현했습니다.
    *   이는 모든 사용자에게 공정한 리소스를 할당하고 서비스의 안정성을 보장합니다.

2.  **API 문서화 (Swagger / OpenAPI)**:
    *   `springdoc-openapi` 라이브러리를 도입하여, 컨트롤러와 DTO에 어노테이션을 추가하는 것만으로 **API 명세를 자동으로 생성**했습니다.
    *   이를 통해 프론트엔드 개발자와의 협업 효율성을 높이고, API의 유지보수성을 향상시켰습니다.

---

### ✅ 4. 프론트엔드 사용자 경험(UX) 개선

*   AI 기능과 관련된 프론트엔드 UI 및 인터랙션을 개선하여 사용자가 더 편리하게 서비스를 이용할 수 있도록 했습니다.

1.  **AI 기능 UI**:
    *   **AI 어시턴트 패널**: 드래그, 최소화/최대화가 가능한 채팅 패널을 구현했습니다.
    *   **코드 리뷰 모달**: AI 코드 리뷰 요청을 위한 별도의 모달 UI를 제공했습니다.

2.  **사용 편의성 및 피드백 강화**:
    *   **토큰 사용량 추정**: AI 요청 전, 예상 토큰 사용량을 실시간으로 계산하여 보여줌으로써 비용 투명성을 제공했습니다.
    *   **상세한 로딩 상태**: 단순한 스피너 대신, "코드 분석 중..."과 같이 다양한 로딩 메시지를 보여주어 대기 시간의 지루함을 줄였습니다.
    *   **웹 접근성**: ARIA 속성을 추가하여 보조 기술 사용자의 접근성을 개선했습니다.

---

### 📌 요약

*   **Spring AI**를 통해 **LLM을 손쉽게 통합**하고, **구조화된 JSON 응답**과 **가드레일**을 통해 AI의 활용성과 안정성을 높였습니다.
*   AI 대화 기록을 **DB에 저장**하고, **대화 컨텍스트를 유지**하여 더 지능적인 상호작용을 구현했습니다.
*   **API 레이트 리미터**와 **Swagger 문서화**를 통해 백엔드 서비스의 **안정성과 유지보수성**을 강화했습니다.
*   프론트엔드는 **토큰 사용량 추정**, **상세한 로딩 피드백** 등 **사용자 경험(UX)을 중심**으로 AI 관련 기능을 고도화했습니다.